# -*- coding: utf-8 -*-
"""Flux-Text-to-Image.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N8lYtU03Ij9sCW7yDCVMpuDVHtWsD5sh

# **Text-to-Image using Flux**
# Introduction
In this notebook, we will use the Flux model from Black Forest Labs to generate images from text prompts. The Flux model is available on Hugging Face and can be accessed via the diffusers library.

Huggingface Model: https://huggingface.co/black-forest-labs

Checkout the site: https://blackforestlabs.ai/

Checkout GitHuh: https://github.com/black-forest-labs/flux

# Prerequisites
Before we start, ensure you have the necessary libraries installed. We will use diffusers for the model and torch for tensor operations.
"""

!pip install -U diffusers
!pip install torch

"""# Import Libraries
First, we need to import the required libraries.
"""

import torch
from diffusers import FluxPipeline, DPMSolverMultistepScheduler

"""# Load the Model
We will load the Flux model using the FluxPipeline class from the diffusers library. Make sure to use the appropriate model checkpoint.
"""

import torch
from diffusers import FluxPipeline
from huggingface_hub import notebook_login

# Log in to your Hugging Face account
notebook_login()

# Check and use GPU if available
if torch.cuda.is_available():
    device = "cuda"
else:
    device = "cpu"
    print("Warning: GPU not detected. Using CPU instead. Performance may be slower.")

# Load the model with appropriate precision and scheduler for faster inference
pipe = FluxPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-dev",
    torch_dtype=torch.bfloat16,  # Use bfloat16 for faster computation on GPU
    revision="main",  # Use the 'main' branch for updated model
    scheduler=DPMSolverMultistepScheduler.from_pretrained(
        "black-forest-labs/FLUX.1-dev", subfolder="scheduler"
    ),
).to(device)

"""# Define the Prompt
Next, we define the text prompt that we want to convert into an image.
We will use a random seed to ensure reproducibility. The generator will be set to use CUDA for faster computation.
"""

prompt = "A cat holding a sign that says Hello India"

generator = torch.Generator('cuda').manual_seed(0)

"""# Generate the Image
Now, we generate the image using the pipe object. We can specify various parameters such as image dimensions, guidance scale, and the number of inference steps.
"""

# Generate the image with reduced dimensions, steps, and lower guidance scale
image = pipe(
    prompt,
    height=512,
    width=512,
    guidance_scale=2,
    num_inference_steps=25,
    max_sequence_length=512,
    generator=generator
).images[0]

"""# Displaying the image"""

from IPython.display import display

# Embed the image
display(image)

"""# Save the Image
Finally, we save the generated image to a file.
"""

image.save("flux-dev.png")

"""## Conclusion

This notebook demonstrated the process of generating images from text prompts using the Flux model from Black Forest Labs. We explored the necessary steps, including installing required libraries, loading the model, defining prompts, and generating images.

**Key Takeaways:**

* **Flux Model:** We successfully utilized the Flux model, a powerful text-to-image AI, to create images from descriptive text prompts.
* **Hugging Face Integration:** The integration with Hugging Face's `diffusers` library simplified the model access and usage.
* **Customization:** We explored various parameters like image dimensions, guidance scale, and inference steps to control the image generation process.
* **Hardware Acceleration:** Leveraging GPU acceleration significantly reduced the image generation time.
* **Image Embedding:** We learned how to embed the generated images directly into the Colab notebook for immediate visualization.

**Potential Applications:**

This technology opens up numerous possibilities, including:

* **Creative Content Generation:** Artists and designers can use text-to-image AI to quickly generate ideas and visual concepts.
* **Content Marketing:** Marketers can create unique visuals for their campaigns based on textual descriptions.
* **Prototyping and Design:** Product designers can visualize their ideas by generating images from product descriptions.
* **Education and Research:** Researchers can use text-to-image models to explore the relationship between language and visual representation.

**Challenges and Future Directions:**

While impressive, text-to-image technology is still evolving. Some challenges include:

* **Fine-grained Control:** Achieving precise control over the generated image details remains an area of improvement.
* **Bias and Ethical Considerations:** Addressing potential biases in the training data and ensuring responsible use of the technology are critical.
* **Computational Resources:** Generating high-resolution images requires significant computational power.

Despite these challenges, the rapid advancements in this field hold immense promise for future applications.

**Acknowledgments:**

We extend our gratitude to the developers of the Flux model at Black Forest Labs for making this powerful technology accessible. Their contributions to open-source AI research are invaluable. We also thank the Hugging Face team for providing the `diffusers` library, which simplified the integration and usage of the Flux model within this notebook.

"""